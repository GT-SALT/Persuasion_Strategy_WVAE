{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from bertVAE import *\n",
    "import pickle\n",
    "from read_data_bert_vae import *\n",
    "from utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = '../data/kiva/'\n",
    "n_labeled_data = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = torch.load(data_path + 'model_last.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 0, 1: 1, 2: 0, 3: 2, 4: 3, 5: 4, 6: 0, 7: 0, 8: 5, 9: 6}\n",
      "vocab size:  30522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:02<00:00, 356.13it/s]\n",
      "100%|██████████| 2000/2000 [00:21<00:00, 91.68it/s] \n",
      "100%|██████████| 400/400 [00:01<00:00, 364.98it/s]\n",
      "100%|██████████| 400/400 [00:01<00:00, 338.82it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "#Labeled: 1000, Unlabeled 2000, Val 400, Test 400, N class 7, 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_labeled_dataset, train_unlabeled_dataset, val_dataset, test_dataset, vocab_size, n_labels, doc_labels = read_data(\n",
    "        data_path=data_path, n_labeled_data=n_labeled_data, n_unlabeled_data=2000, \n",
    "    max_seq_num=6, max_seq_len=64, embedding_size=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "labeled_trainloader = Data.DataLoader(\n",
    "        dataset=train_labeled_dataset, batch_size=4, shuffle=False)\n",
    "unlabeled_trainloader = Data.DataLoader(\n",
    "    dataset=train_unlabeled_dataset, batch_size=4, shuffle=False)\n",
    "    \n",
    "val_loader = Data.DataLoader(\n",
    "        dataset=val_dataset, batch_size=4, shuffle=False)\n",
    "test_loader = Data.DataLoader(\n",
    "        dataset=test_dataset, batch_size=4, shuffle=False)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HierachyVAE(\n",
       "  (encoder): Encoder(\n",
       "    (bert): BertModel(\n",
       "      (embeddings): BertEmbeddings(\n",
       "        (word_embeddings): Embedding(30522, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (token_type_embeddings): Embedding(2, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (encoder): BertEncoder(\n",
       "        (layer): ModuleList(\n",
       "          (0): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (1): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (2): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (3): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (4): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (5): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (6): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (7): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (8): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (9): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (10): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (11): BertLayer(\n",
       "            (attention): BertAttention(\n",
       "              (self): BertSelfAttention(\n",
       "                (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "              (output): BertSelfOutput(\n",
       "                (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "                (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "                (dropout): Dropout(p=0.1, inplace=False)\n",
       "              )\n",
       "            )\n",
       "            (intermediate): BertIntermediate(\n",
       "              (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            )\n",
       "            (output): BertOutput(\n",
       "              (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (pooler): BertPooler(\n",
       "        (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (activation): Tanh()\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (hidden_to_mu): Linear(in_features=135, out_features=128, bias=True)\n",
       "  (hidden_to_logvar): Linear(in_features=135, out_features=128, bias=True)\n",
       "  (hidden_linear): Linear(in_features=768, out_features=128, bias=True)\n",
       "  (classifier): Linear(in_features=768, out_features=7, bias=True)\n",
       "  (predictor): Predictor(\n",
       "    (embedding): Linear(in_features=7, out_features=128, bias=False)\n",
       "    (lstm): LSTM(128, 64, batch_first=True)\n",
       "    (w_proj): Linear(in_features=128, out_features=128, bias=True)\n",
       "    (softmax): Softmax(dim=2)\n",
       "    (predict): Linear(in_features=64, out_features=5, bias=True)\n",
       "  )\n",
       "  (generator): Generator(\n",
       "    (lstm): LSTM(903, 1024, batch_first=True)\n",
       "    (linear): Linear(in_features=1024, out_features=30522, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "count = 0\n",
    "correct = 0\n",
    "\n",
    "score_vectors = []\n",
    "doc_length = []\n",
    "strategies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, l, y, mask1, mask2, mask3, mask4, mid, sent_len, doc_len) in enumerate(val_loader):\n",
    "\n",
    "        batch_size = l.shape[0]\n",
    "        seq_num = x.shape[1]\n",
    "        seq_len = x.shape[2]\n",
    "        \n",
    "        temp = l.view(-1, 1).long()\n",
    "        #print(temp.shape)\n",
    "        l_one_hot = torch.zeros(batch_size*seq_num, n_labels).cuda()\n",
    "        #print(l_one_hot.shape)\n",
    "        \n",
    "        for i in range(0, len(temp)):\n",
    "            if temp[i] != 10:\n",
    "                l_one_hot[i][temp[i]] = 1\n",
    "                \n",
    "        l_one_hot = l_one_hot.view(batch_size, seq_num, n_labels)\n",
    "        \n",
    "        x, doc_labels, y,  l = x.cuda(), y.cuda(), l_one_hot.cuda() , l.cuda()\n",
    "        \n",
    "        mask1, mask2 = mask1.cuda(), mask2.cuda()\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        seq_num = x.shape[1]\n",
    "        seq_len = x.shape[2]\n",
    "        \n",
    "        n_labels = y.shape[-1]\n",
    "\n",
    "        x = x.view(batch_size * seq_num, seq_len)\n",
    "        y = y.view(batch_size*seq_num, model.n_class)\n",
    "        mask1 = mask1.view(batch_size*seq_num)\n",
    "        mask2 = mask2.view(batch_size * seq_num)\n",
    "\n",
    "        sent_len = sent_len.view(batch_size * seq_num)\n",
    "\n",
    "        q_y, encoder_hidden = model.encode(x, sent_len)\n",
    "        \n",
    "        \n",
    "\n",
    "        y_sample = model.gumbel_softmax(q_y, 1, True)\n",
    "\n",
    "        y_in = y * mask1.view(-1, 1).float() + y_sample * mask2.view(-1, 1).float()\n",
    "        \n",
    "        \n",
    "        #print(y_in.shape)\n",
    "        #print(encoder_hidden.shape)\n",
    "        \n",
    "        hidden = torch.cat([encoder_hidden, y_in], dim = -1)\n",
    "        \n",
    "        mu = model.hidden_to_mu(hidden)\n",
    "        logvar = model.hidden_to_logvar(hidden)\n",
    "        \n",
    "        y_in2 = y * mask1.view(-1,1).float() + F.softmax(q_y, dim=-1) * mask2.view(-1,1)\n",
    "        \n",
    "        y_in3 = F.softmax(q_y, dim=-1)\n",
    "\n",
    "        z = model.gaussian_sample(mu, logvar, batch_size*seq_num)\n",
    "        \n",
    "        t, strategy_embedding = model.predictor(\n",
    "            y_in2.view(batch_size, seq_num, model.n_class), encoder_hidden.view(batch_size, seq_num, model.z_size), doc_len)\n",
    "        \n",
    "        #print(model.predictor.w_score.shape)\n",
    "        #print(model.predictor.w_score)\n",
    "        \n",
    "        _, predicted = torch.max(t.data, 1)\n",
    "        \n",
    "        correct += (np.array(predicted.cpu()) == np.array(doc_labels.cpu())).sum()\n",
    "        count += len(predicted)\n",
    "        \n",
    "        \n",
    "        score_vectors.append(model.predictor.w_score)\n",
    "        doc_length.append(doc_len)\n",
    "        strategies.append(l)\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "correct = 0\n",
    "\n",
    "score_vectors = []\n",
    "doc_length = []\n",
    "strategies = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for batch_idx, (x, l, y, mask1, mask2, mask3, mask4, mid, sent_len, doc_len) in enumerate(unlabeled_trainloader):\n",
    "\n",
    "        batch_size = l.shape[0]\n",
    "        seq_num = x.shape[1]\n",
    "        seq_len = x.shape[2]\n",
    "        \n",
    "        temp = l.view(-1, 1).long()\n",
    "        #print(temp.shape)\n",
    "        l_one_hot = torch.zeros(batch_size*seq_num, n_labels).cuda()\n",
    "        #print(l_one_hot.shape)\n",
    "        \n",
    "        for i in range(0, len(temp)):\n",
    "            if temp[i] != 10:\n",
    "                l_one_hot[i][temp[i]] = 1\n",
    "                \n",
    "        l_one_hot = l_one_hot.view(batch_size, seq_num, n_labels)\n",
    "        \n",
    "        x, doc_labels, y,  l = x.cuda(), y.cuda(), l_one_hot.cuda() , l.cuda()\n",
    "        \n",
    "        mask1, mask2 = mask1.cuda(), mask2.cuda()\n",
    "        \n",
    "        batch_size = x.shape[0]\n",
    "        seq_num = x.shape[1]\n",
    "        seq_len = x.shape[2]\n",
    "        \n",
    "        n_labels = y.shape[-1]\n",
    "\n",
    "        x = x.view(batch_size * seq_num, seq_len)\n",
    "        y = y.view(batch_size*seq_num, model.n_class)\n",
    "        mask1 = mask1.view(batch_size*seq_num)\n",
    "        mask2 = mask2.view(batch_size * seq_num)\n",
    "\n",
    "        sent_len = sent_len.view(batch_size * seq_num)\n",
    "\n",
    "        q_y, encoder_hidden = model.encode(x, sent_len)\n",
    "        \n",
    "        \n",
    "\n",
    "        y_sample = model.gumbel_softmax(q_y, 1, True)\n",
    "\n",
    "        y_in = y * mask1.view(-1, 1).float() + y_sample * mask2.view(-1, 1).float()\n",
    "        \n",
    "        \n",
    "        #print(y_in.shape)\n",
    "        #print(encoder_hidden.shape)\n",
    "        \n",
    "        hidden = torch.cat([encoder_hidden, y_in], dim = -1)\n",
    "        \n",
    "        mu = model.hidden_to_mu(hidden)\n",
    "        logvar = model.hidden_to_logvar(hidden)\n",
    "        \n",
    "        y_in2 = y * mask1.view(-1,1).float() + F.softmax(q_y, dim=-1) * mask2.view(-1,1)\n",
    "        \n",
    "        y_in3 = F.softmax(q_y, dim=-1)\n",
    "\n",
    "        z = model.gaussian_sample(mu, logvar, batch_size*seq_num)\n",
    "        \n",
    "        t, strategy_embedding = model.predictor(\n",
    "            y_in2.view(batch_size, seq_num, model.n_class), encoder_hidden.view(batch_size, seq_num, model.z_size), doc_len)\n",
    "        \n",
    "        #print(model.predictor.w_score.shape)\n",
    "        #print(model.predictor.w_score)\n",
    "        \n",
    "        _, predicted = torch.max(t.data, 1)\n",
    "        \n",
    "        correct += (np.array(predicted.cpu()) == np.array(doc_labels.cpu())).sum()\n",
    "        count += len(predicted)\n",
    "        \n",
    "        \n",
    "        score_vectors.append(model.predictor.w_score)\n",
    "        doc_length.append(doc_len)\n",
    "        strategies.append(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4942953020134228"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correct/count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c_score = []\n",
    "s_score = []\n",
    "for i in range(0, len(score_vectors)):\n",
    "    for j in range(0, score_vectors[i].shape[0]):\n",
    "        for m in range(0, doc_length[i][j]):\n",
    "            c_score.append(score_vectors[i][j][m][1].cpu() )\n",
    "            s_score.append(score_vectors[i][j][m][0].cpu() )\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Content strategy comparison\n",
    "# Strategy vs strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9765])"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(c_score)/len(c_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.0235])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum(s_score)/len(s_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats, integrate\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fdecc3e2c18>"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "#sns.distplot(c_score, color=\"b\", bins=10, rug=True)\n",
    "sns.distplot(c_score, hist=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7fde93ff9240>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAAD4CAYAAAD1jb0+AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbgUlEQVR4nO3de3Bc53nf8e8DLC7ElQQByqRuoCzLEqUqtQq7cmwntWm7qm/qTNNUmjqxI9WcpJPYaZJx7brTuO1kGk/a1Ok044S25UvjSm7ktFZSx7UtWZXqSLIg607SulAURZESAYEkgMVlsbtP/zh7QAgCiN2zZ3fPOfh9ZjjC7p7d8x4B/PHFc96LuTsiIpI+ba1ugIiIRKMAFxFJKQW4iEhKKcBFRFJKAS4iklK5Zp5seHjYR0dHm3lKEZHUe+ihhybdfWT1800N8NHRUcbHx5t5ShGR1DOz59d6XiUUEZGUUoCLiKSUAlxEJKUU4CIiKaUAFxFJKQW4iEhKKcBFRFJqUwd4qayldEUkvZo6kafV5gslPnLLj3l+Ks+Z+SUWi2W+8E+v4bqrdra6aSIiNdtUPfDnJvP8+MgUl53Xzy9dezEAB0/MtLhVIiLRbKoAPzVXAODX33kpn3n/Hga3dCw/JyKSNpsqwKfyQVhv6+0EYKinc/k5EZG02VQBHva2t/UEAb6tt1M9cBFJrc0V4PklALb2dABBkE9VnhMRSZvNFeBzBQa6c3S0B5c91NvBKZVQRCSlNlWAT+ULDFXq3xCUUKbmCrhrPLiIpM+mCvBTcwW29pwN8KGeTgrFMnOFUgtbJSISzaYL8NU9cEAjUUQklTZXgOeXlkegwNnRKBqJIiJptKkCPKiBdyw/Dr9WD1xE0mjDADezW8zspJk9scZrv21mbmbDjWlefBaWSswvlV5VAw974KfnNJRQRNKnmh74V4HrVj9pZhcC7wWOxtymhgjLJCtr4EOqgYtIim0Y4O5+DzC1xkv/GfgkkIoxeMvT6Ff0wAe6O2gz1cBFJJ0i1cDN7HrgRXd/tIpj95nZuJmNT0xMRDldLMJZmCt74G1tVpmNqQAXkfSpOcDNrAf4V8C/qeZ4d9/v7mPuPjYyMlLr6WIztbwOSserntd6KCKSVlF64K8HdgOPmtkR4ALgJ2b2ujgbFrfTc69eiTCkFQlFJK1q3pHH3R8HdoSPKyE+5u6TMbYrdmFIb92yugfewZHJuVY0SUSkLtUMI7wVuA94o5kdM7ObG9+s+J3KFxjc0kGu/dWXPFRZD0VEJG027IG7+40bvD4aW2saaGpu6VU3MEPbejo5lQ8WtDKzFrRMRCSaTTMT81S+sLwO+EpDvZ0Uy87MYrEFrRIRiW7zBPhcgaGetXvggNYFF5HU2TwBni+8ZgQKBDcxQbMxRSR9Nk2AT61aSjak9VBEJK02RYDPF0osLJXXrYGDeuAikj6bIsCXF7JaqwbeqzXBRSSdNkWALy9ktUYJpb8rR67N1AMXkdTZFAG+1lKyITPTeigikkqbIsDPLiX72ho4aD0UEUmnTRHg4QiTbWvUwCEYShguNysikhabIsCn8gXMYHDLOj1wrYciIim0KQL81NzaC1mFwvVQRETSZFME+FR+7Wn0oaHKTcxyORW7w4mIAJskwE/Nrb2QVWhbTydlh+kF1cFFJD02R4Dn115KNhSuh3JK0+lFJEU2R4DPFdYdgQJnR6doKKGIpEnmA9zdgxr4OXrg4Wu6kSkiaZL5AJ9fKrFYLLO1mh64hhKKSIpkPsDDuvZQ7/o3MdUDF5E0qmZT41vM7KSZPbHiuT8ws0Nm9piZ/U8z29rYZkYXhvK5euA9ne10tJtuYopIqlTTA/8qcN2q574PXOXuVwNPAZ+OuV2xCYcGDnSv3wM3M/q6cuS1L6aIpMiGAe7u9wBTq577nruHaXc/cEED2haL/GIJgP7u3DmP6+tWgItIusRRA78J+Ov1XjSzfWY2bmbjExMTMZyuNrOLQQ+8t+vcAd7bmdPO9CKSKnUFuJl9BigC31jvGHff7+5j7j42MjJSz+kimV0IQrlvgwDvVw9cRFLm3Kl2Dmb2UeADwF53T+wiIrOVEspGAd7bldNEHhFJlUg9cDO7Dvgk8CF3n4u3SfGaXVyivc3o7jj3pfZ15ZZ76yIiaVDNMMJbgfuAN5rZMTO7GfivQD/wfTN7xMz+pMHtjCy/WKKvK4eZnfO4/u4csyqhiEiKbFhCcfcb13j6yw1oS0PMLBQ3LJ9AcBNTAS4iaZL5mZj5xeoCvK87x1yhRElrgotISmQ+wGcXi/R2tW94XBjy+YJ64SKSDpkP8JnFIn3nmIUZCgNcNzJFJC0yH+BBCWXjHng40UdjwUUkLTIf4LNV3sTsq0y112xMEUmLzAd40APfuITSrx64iKRMpgPc3Zkt1FZCUQ1cRNIi0wE+VyjhfrY8ci7LNzHVAxeRlMh0gIdhvNFKhKAAF5H0yXSAz1S5EiGohCIi6ZPpAA9vSFYT4J25NrpybcxqIo+IpESmA3y2hgAPj1MPXETSYnMEeBU3McPjNIxQRNIi2wFeQw0ctCKhiKRLpgM8XJiq6hJKd275xqeISNJlOsDDMK5mGCEEQa/VCEUkLTId4LOLRTraja5cdZepm5gikiaZDvD8YpHeKrZTC/V155Y3QRYRSbpq9sS8xcxOmtkTK54bMrPvm9nTlf9ua2wzo6l2JcJQX1eO2cWlBrZIRCQ+1fTAvwpct+q5TwF3uvsbgDsrjxNntsrt1EJ9XTkWlsoUS+UGtkpEJB4bBri73wNMrXr6euBrla+/BvzDmNsVi1oD/OymDiqjiEjyRa2Bn+fuJypfvwSct96BZrbPzMbNbHxiYiLi6aLJLxarnsQDZ9cEn1EZRURSoO6bmO7uwLpbubv7fncfc/exkZGRek9Xk5nKTcxqhWGvHriIpEHUAH/ZzHYCVP57Mr4mxWd2objcq67G8oqE6oGLSApEDfA7gI9Uvv4I8O14mhOvfK098OUAVw9cRJKvmmGEtwL3AW80s2NmdjPw+8B7zOxp4N2Vx4lSLjv5QqnmUSigNcFFJB02TDd3v3Gdl/bG3JZYhVPi+2u4iXm2Bq4AF5Hky+xMzFq2Uwv1dYajUBTgIpJ8mQ3wWnbjCfVWdq9XCUVE0iCzAV7LfpihXHsbWzratSKhiKRCZgM8HMtdy0QeCEouWhNcRNIgswEejuXu7awtwPu1rZqIpERmAzzsRdcyCgWCOri2VRORNMhsgEe5iRker5uYIpIGmQ3wKMMIAfq6OtQDF5FUyHCAl+jMtdFZ5XZqoT6VUEQkJTIc4Es1l08gGLWim5gikgaZDfD8Ym3roIR6u3KaiSkiqZDZAJ9ZqG0lwlB/V45CsUyhqG3VRCTZMhvgs4tLNa0FHjq7rZp64SKSbJkN8PxiqeZZmLByTXAFuIgkW2YDfLbGzRxC4cQfBbiIJF2mAzzqTczw/SIiSZbdAF8o0ldZHrYWKqGISFpkMsBLZWd+qURfV0fN79W2aiKSFpkM8LPT6CP0wLWtmoikRF0Bbmb/wsyeNLMnzOxWM+uOq2H1CAO81pUIQSUUEUmPyAFuZucDHwfG3P0qoB24Ia6G1ePsSoS1l1DC9cO1qYOIJF29JZQcsMXMckAPcLz+JtUvDN8oJZS2NqO3s10lFBFJvMgB7u4vAv8ROAqcAM64+/dWH2dm+8xs3MzGJyYmore0BlHXAg/1dWtbNRFJvnpKKNuA64HdwC6g18w+vPo4d9/v7mPuPjYyMhK9pTU4uxtP7SWU8H0zlS3ZRESSqp4SyruB59x9wt2XgL8AfjaeZtVneiEI34Et0Xrg/eqBi0gK1BPgR4FrzazHzAzYCxyMp1n1makEeD098GkFuIgkXD018AeA24GfAI9XPmt/TO2qy8xCkTaD3s7ab2ICDHTnmJlXCUVEki1ajaHC3X8X+N2Y2hKb6flgN57gF4PaqQcuImmQyZmYMwtFBrZEK59ApQe+oB64iCRbJgN8eqEYuf4NwU3MxWKZxWIpxlaJiMQrkwE+s7AUaRp9KAx/jUQRkSTLZIBPLxQZqKMHHg4/VICLSJJlMsBnFpYYqKcH3hX2wFUHF5HkymiAF+ssoagHLiLJl7kAd/dKDbyem5jBe6c1FlxEEixzAZ4vlCh79Gn0oBq4iKRD5gK83mn0K987rRq4iCRYBgM8+m48oXAZWvXARSTJMhfgYd26nh54e5vR16UVCUUk2TIX4GHo1jOMMHy/SigikmSZC/DpGGrg4fs1DlxEkixzAR5XD1ybOohI0mUuwM/uxlNvD1wBLiLJlrkAn1ko0tFudOXqu7RgTXCVUEQkuTIY4MEszKibOYQGtqgHLiLJlrkAn56vbx2UUHgT091jaJWISPzqCnAz22pmt5vZITM7aGZvjathUQUrEdZX/4agBr5UchaL5RhaJSISv3q7qn8EfNfdf8HMOoGeGNpUl3pXIgytXNCquyPa5sgiIo0UuQduZoPAzwFfBnD3grufjqthUcUV4OEwRG1uLCJJVU8JZTcwAXzFzB42sy+ZWe/qg8xsn5mNm9n4xMREHaerznSdS8mGBrq1qYOIJFs9AZ4DrgG+4O5vAvLAp1Yf5O773X3M3cdGRkbqOF11ZurcTi2kTR1EJOnqCfBjwDF3f6Dy+HaCQG+ZUtmZXYy5Bq4euIgkVOQAd/eXgBfM7I2Vp/YCB2JpVUSzMSwlG9KmDiKSdPUm3W8A36iMQDkM/Er9TYourmn0cLYHrhq4iCRVXQHu7o8AYzG1pW5xLWQF0NvZTpupBy4iyZWpmZhxbKcWMgs2ddDGxiKSVJkK8OkYa+AQlGLUAxeRpMpUgIc98DiGEUK4IqECXESSKWMBHm8PPFgTXCUUEUmmTAV4HBsarxTsi6keuIgkU6YCfGaxSHdHG511buYQ0r6YIpJk2QrwmNZBCQ1oWzURSbBMBfh0TCsRhrSpg4gkWbYCfD7eHnh/d46yQ75Qiu0zRUTikqkAD1YijLcHHnyu6uAikjwZC/B4tlMLaUErEUmyTAV4I2rgoB64iCRTpgI8GIUSZ4BrWzURSa7MBPhSqczCUjneEkoY4FrQSkQSKDMBHvc0eli5L6Z64CKSPJkJ8Lin0a/8LAW4iCRRZgJ8eTOHGHbjCXV3tJFrM93EFJFEylCAhz3w+EooZkZ/d04bG4tIImUmwKcbEOAQ9Oin51VCEZHkqTvAzazdzB42s7+Ko0FRnZ4LAnwwxhIKwLaeTk7NFWL9TBGROMTRA/8EcDCGz6nL5OwiAMN9XbF+7kh/FxMzi7F+pohIHOoKcDO7AHg/8KV4mhPdxMwiA905ujvaY/1cBbiIJFW9PfDPA58EyusdYGb7zGzczMYnJibqPN36JmYXGemPt/cNQY9+aq5AsbTuJYqItETkADezDwAn3f2hcx3n7vvdfczdx0ZGRqKebkMTM40J8JH+LtxhKq86uIgkSz098LcBHzKzI8BtwLvM7M9iaVUEQYB3x/65I5Wa+kmVUUQkYSIHuLt/2t0vcPdR4AbgLnf/cGwtq9HkbGE5bOM00t8JBCUaEZEkycQ48LlCkdnFYmNKKH1Br35SPXARSZhYZr24+93A3XF8VhSTM0F9erivM/bPHlYPXEQSKhM98InZBYCG9MB7OnP0deU0lFBEEicbAV4J10YEOAQ9+8lZjUIRkWRRgFchmMyz0JDPFhGJKhsBPlugzWB7byMDXCUUEUmWbAT4zCJDvV20t1lDPn+4TwEuIsmTmQBvVPkEgsk80wtFFoulhp1DRKRW2Qjw2cWGDCEMhf846EamiCRJJgJ8ssE98HCJWpVRRCRJUh/g7t74EkrYA1eAi0iCpD7Ap+eLFErlhqyDEgoDXLMxRSRJUh/gYag2sge+vVJfVwlFRJIk/QHe4Ek8AF25dga3dCjARSRR0h/glR74jgYGOAT/QEyqhCIiCZL+AJ9pzGbGq41oMo+IJEwmAryj3Rjc0tHQ8wz3d+kmpogkSiYCfKSvC7PGTKMPjfR1aRihiCRK+gO8QbvRrzbS30W+UCK/WGz4uUREqpH6AG/0LMzQ2en06oWLSDJEDnAzu9DMfmhmB8zsSTP7RJwNq1azeuDDGgsuIglTz56YReC33f0nZtYPPGRm33f3AzG1bUOlsvPK7GJDZ2GG1AMXkaSJ3AN39xPu/pPK1zPAQeD8uBpWjal8gbI3dhJPaHk6vXrgIpIQsdTAzWwUeBPwwBqv7TOzcTMbn5iYiON0y5o1BhxgqKcTMwW4iCRH3QFuZn3At4DfdPfp1a+7+353H3P3sZGRkXpP9yrNWAcllGtvY3tvJxNaE1xEEqKuADezDoLw/oa7/0U8TareZBPWQVkp2FpNmxuLSDLUMwrFgC8DB939D+NrUvWOTs1hBjv6u5tyvouGejg8mW/KuURENlJPD/xtwC8B7zKzRyp/3hdTu6ry5PFpLhnuZUtne1POt2fXAM9N5pkraDKPiLRe5GGE7v7/gMbOX9/AgeNnGBsdatr5rtw1iDscPDHD37l4W9POKyKyltTOxDyVL3D8zAJX7hpo2jn3VM514MRr7tWKiDRdagM8DNErdw027Zy7BrvZ2tPBgeNnmnZOEZH1pDbAn6yE6J4m9sDNjD07BzhwXD1wEWm9FAf4NDsHuxnq7Wzqea/cNcChl2YolspNPa+IyGqpDvBm1r9De3YNsFgsazihiLRcKgN8vlDi8MQse5pY/w6FNfcnVQcXkRZLZYAffGmastOSHvglw7105dpUBxeRlktlgD95PByB0vwAz7W3cfnr+pfbICLSKqkM8APHzzC4pYPzt25pyfn37BrgwIlp3L0l5xcRgZQGeHgDs9EbGa9nz65BTs8tcfyMFrYSkdZJXYAvlcocemmmJeWT0J6dlRmZKqOISAulLsAPT+QpFMtNnYG52hU7+zHTSBQRaa3UBXgYmq3sgfd05tg93KsbmSLSUqkL8O8+8RID3UGAttJbRof40TOTvKJNjkWkRVIV4E+8eIbvHXiZm96+m1x7a5v+z95xCfNLJb5473MtbYeIbF6pCvDP/+BpBrpz3PT23a1uCpfu6OODV+/i6/cdYSqvfTJFpPkib+jQbI8fO8MPDr7Mb73nMga6O1rdHAA+vvdS/vKx43zx3sP8y+sub3VzRCSiwxOz3HXoJHcePMmLp+cxC3arOW+gm3dfcR7v2XMeoy0u264lNQH++R88xeCWDn7lbaOtbsqyS3f084Grd/H1vznCx95xSdNXRhSR6BaLJb79yHG+8qMjHKzsL3D56/q55qKtOFB2ePrlGX7vOwf5ve8cZM/OAW56+24++DM76co1ZxvHjaQiwB994TR3HjrJ77z3MvoT0vsOffxdl/JXjx3nT+95lk//gyta3RwR2cBLZxa47cGj/Nn9R5mcXeTy1/Xz2Q/uYe8V53HhUM9rjn9hao7vHXiZbz54lN/580f53HcP8cvXXsw/efOF7Bhozobq67F6poOb2XXAHwHtwJfc/ffPdfzY2JiPj4/XfJ7fvO1h7n5qgns/+c7EBTjAJ257mG8/cpwP/swu/vX7r+C8Fn9TReTVpheW+JtnXuH2h45x16GXKTv8/GUjfOwdl/C2S7dXNavb3bn36Um+eO9h7n16kvY2Y+/lO/jHYxfy1tdvp6+rcf1hM3vI3cde83zUADezduAp4D3AMeBB4EZ3P7Dee6IG+HyhxE9fnuFvX7g1UlsbbWGpxBfufpYv/N9n6Wgzbnr7bq7cNcju4V7O37aFrlwbuTZr2dR/kVq4O+7gKx+vc6wR7FQV/JeW/Iy7O6Wyky+UmCsUmV0o8uLpeV44Nc/zk3kefP4Ujx87TdlhuK+LXxy7gBvefBEXbX9tb7taz03mue3Bo3zroWNMzhZobzOuvmCQt4wOcfH24O/9rsFu+rs76Olqp7czR3tb9P83jQjwtwKfdfe/X3n8aQB3/w/rvSdqgKfF86/k+bd/eYC7Dp18zWtm0NHedvYHHWPlz7qiXeqx3t/ilX+9nRXB7K9+HIZ0HOuzmUHbqlC3Fa9B8PPPqueC59e4hlXXs7LdpXIQ3uvpbG/j6gsG+dnXb+fa12/nzaNDdMQ4BLlQLPPj56a47/Ak9z37Co8dO0NxnfZ85aNv5p2X74h0nvUCvJ4+//nACyseHwP+7hon3gfsqzycNbOf1nHOOA0Dk61uRMx0Temga2qip4FvRXtrrNf0rs/V9faL13qy4Tcx3X0/sL/R56mVmY2v9S9amuma0kHXlA5puKZ6fpd4EbhwxeMLKs+JiEgT1BPgDwJvMLPdZtYJ3ADcEU+zRERkI5FLKO5eNLNfB/4PwTDCW9z9ydha1niJK+vEQNeUDrqmdEj8NdU1DlxERFonVYtZiYjIWQpwEZGUynyAm9l1ZvZTM3vGzD61xutdZvbNyusPmNlo81tZmyqu6bfM7ICZPWZmd5rZmmNIk2Sja1px3D8yMzezRA/vquZ6zOwXK9+nJ83svze7jbWq4ufuIjP7oZk9XPnZe18r2lkLM7vFzE6a2RPrvG5m9l8q1/yYmV3T7DaeUzBtNpt/CG6uPgtcAnQCjwJ7Vh3zz4E/qXx9A/DNVrc7hmt6J9BT+frXsnBNleP6gXuA+4GxVre7zu/RG4CHgW2Vxzta3e4Yrmk/8GuVr/cAR1rd7iqu6+eAa4An1nn9fcBfE0wSvRZ4oNVtXvkn6z3wtwDPuPthdy8AtwHXrzrmeuBrla9vB/Zashct2fCa3P2H7j5XeXg/wRj9JKvm+wTw74HPAQvNbFwE1VzPx4A/dvdTAO7+2vUXkqWaa3Ig3Kx2EDjexPZF4u73AFPnOOR64OseuB/YamY7m9O6jWU9wNea7n/+ese4exE4A2xvSuuiqeaaVrqZoAeRZBteU+VX1wvd/X83s2ERVfM9ugy4zMx+ZGb3V1b2TLJqrumzwIfN7BjwHeA3mtO0hqr171tTpWI9cInGzD4MjAE/3+q21MPM2oA/BD7a4qbEKUdQRvl7BL8h3WNmf8vdT7e0VfW5Efiqu/+nymJ3/83MrnL3cqsbllVZ74FXM91/+RgzyxH86vdKU1oXTVVLGJjZu4HPAB9y98UmtS2qja6pH7gKuNvMjhDUIu9I8I3Mar5Hx4A73H3J3Z8jWJr5DU1qXxTVXNPNwP8AcPf7gG6CBaHSLNFLhmQ9wKuZ7n8H8JHK178A3OWVuxcJteE1mdmbgD8lCO+k11Zhg2ty9zPuPuzuo+4+SlDX/5C7J3Vt4mp+7v4XQe8bMxsmKKkcbmYja1TNNR0F9gKY2RUEAT7R1FbG7w7glyujUa4Fzrj7iVY3almr76I2+g/BXeSnCO6gf6by3L8jCAAIfsj+HHgG+DFwSavbHMM1/QB4GXik8ueOVre53mtadezdJHgUSpXfIyMoCx0AHgduaHWbY7imPcCPCEaoPAK8t9VtruKabgVOAEsEvxXdDPwq8Ksrvk9/XLnmx5P2c6ep9CIiKZX1EoqISGYpwEVEUkoBLiKSUgpwEZGUUoCLiKSUAlxEJKUU4CIiKfX/AQsg1S6cmPu4AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sns.distplot(s_score, hist=False, norm_hist = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
